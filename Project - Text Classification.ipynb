{
 "cells": [
  {
   "cell_type": "raw",
   "id": "45ae5746",
   "metadata": {},
   "source": [
    "Your task is to:\n",
    "1. Perform Test Classification using Multinomial Naive Bayes(already implemented in sklearn).\n",
    "2. Implement Naive Bayes on your own from scratch for text classification. \n",
    "3. Compare Results of your implementation of Naive Bayes with one in Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb44c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "# instead of putting dataset in folder I directly imported in from sklearn\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "newsgroups_data = fetch_20newsgroups(subset='all')\n",
    "X = newsgroups_data.data\n",
    "y = newsgroups_data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text to feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# Transform counts to tf-idf representation\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41bf38bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Multinomial Naive Bayes Accuracy: 84.75%\n"
     ]
    }
   ],
   "source": [
    "# using in-built naive bayes\n",
    "# Initialize the Multinomial Naive Bayes classifier from sklearn\n",
    "clf_sklearn = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "clf_sklearn.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_sklearn = clf_sklearn.predict(X_test_tfidf)\n",
    "\n",
    "# Check accuracy\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
    "print(f\"Sklearn Multinomial Naive Bayes Accuracy: {accuracy_sklearn * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cffb891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Naive Bayes Accuracy: 85.12%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Custom implementation of Naive Bayes Classifier\n",
    "class NaiveBayesFromScratch:\n",
    "    def __init__(self):\n",
    "        # Placeholder for prior probabilities for each class (P(class))\n",
    "        self.class_probabilities = None\n",
    "        # Placeholder for likelihood probabilities for each feature given a class (P(feature|class))\n",
    "        self.feature_probabilities = None\n",
    "        # Placeholder for unique class labels\n",
    "        self.classes = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Naive Bayes model using training data.\n",
    "        Parameters:\n",
    "        - X: training data (document-term matrix)\n",
    "        - y: training labels (class labels for each document)\n",
    "        \"\"\"\n",
    "        # Get the number of samples (documents) and the number of features (words)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Get the unique class labels (e.g., 20 different newsgroups)\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "\n",
    "        # Initialize arrays to store the prior and likelihood probabilities\n",
    "        # Prior probabilities: P(class) for each class\n",
    "        self.class_probabilities = np.zeros(n_classes)\n",
    "\n",
    "        # Likelihood probabilities: P(feature|class) for each feature (word) and class\n",
    "        # Shape: (number of classes, number of features)\n",
    "        self.feature_probabilities = np.zeros((n_classes, n_features))\n",
    "\n",
    "        # Loop over each class and calculate probabilities\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            # Get all samples (documents) that belong to the current class\n",
    "            X_class = X[y == cls]\n",
    "\n",
    "            # Calculate prior probability P(class) as the proportion of documents in this class\n",
    "            self.class_probabilities[idx] = X_class.shape[0] / float(n_samples)\n",
    "\n",
    "            # Calculate likelihood P(feature|class) using Laplace smoothing:\n",
    "            # (count of word in class + 1) / (total words in class + number of features)\n",
    "            self.feature_probabilities[idx, :] = (X_class.sum(axis=0) + 1) / (X_class.sum() + n_features)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels for a given test dataset.\n",
    "        Parameters:\n",
    "        - X: test data (document-term matrix)\n",
    "        Returns:\n",
    "        - y_pred: predicted class labels for the test data\n",
    "        \"\"\"\n",
    "        y_pred = []  # List to store the predicted labels for each test document\n",
    "\n",
    "        # Loop over each sample in the test data\n",
    "        for x in X:\n",
    "            posteriors = []  # List to store posterior probabilities for each class\n",
    "\n",
    "            # For each class, calculate the posterior probability P(class|document)\n",
    "            for idx, cls in enumerate(self.classes):\n",
    "                # Log of prior probability P(class)\n",
    "                log_prior = np.log(self.class_probabilities[idx])\n",
    "\n",
    "                # Log of likelihood P(document|class): Sum of log(P(word|class)) for all words in the document\n",
    "                log_likelihood = np.sum(x.toarray() * np.log(self.feature_probabilities[idx]))\n",
    "\n",
    "                # Posterior = log(P(class)) + log(P(document|class))\n",
    "                posteriors.append(log_prior + log_likelihood)\n",
    "\n",
    "            # Choose the class with the highest posterior probability\n",
    "            y_pred.append(self.classes[np.argmax(posteriors)])\n",
    "\n",
    "        return np.array(y_pred)  # Return the predicted class labels as an array\n",
    "\n",
    "\n",
    "# Initialize the custom Naive Bayes classifier\n",
    "nb_scratch = NaiveBayesFromScratch()\n",
    "\n",
    "# Train the model using the training data (counts of words in documents)\n",
    "nb_scratch.fit(X_train_counts, y_train)\n",
    "\n",
    "# Predict class labels for the test data\n",
    "y_pred_scratch = nb_scratch.predict(X_test_counts)\n",
    "\n",
    "# Check accuracy of the custom implementation\n",
    "accuracy_scratch = accuracy_score(y_test, y_pred_scratch)\n",
    "print(f\"Custom Naive Bayes Accuracy: {accuracy_scratch * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef8c425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Naive Bayes Accuracy: 84.75%\n",
      "Custom Naive Bayes Accuracy: 85.12%\n"
     ]
    }
   ],
   "source": [
    "# Printing custom naive bayes accuracy and in-built naive bayes accuracy\n",
    "print(f\"Sklearn Naive Bayes Accuracy: {accuracy_sklearn * 100:.2f}%\")\n",
    "print(f\"Custom Naive Bayes Accuracy: {accuracy_scratch * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3f1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
